{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b58048-7d14-4fc6-8085-1fc08c81b4a6",
   "metadata": {
    "id": "75b58048-7d14-4fc6-8085-1fc08c81b4a6"
   },
   "source": [
    "# Fine-Tune Whisper For Multilingual ASR with ü§ó Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ead02-71ed-4be7-bb7a-4efac38775ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here we check the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec925993-b69d-441a-b6a1-3a2038fbea47",
   "metadata": {
    "id": "95048026-a3b7-43f0-a274-1bad65e407b4"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ea9f8-9b61-414e-8885-3033b67c2850",
   "metadata": {
    "id": "e68ea9f8-9b61-414e-8885-3033b67c2850",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets>=2.6.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install librosa\n",
    "!pip install evaluate>=0.30\n",
    "!pip install jiwer\n",
    "!pip install gradio\n",
    "!pip install accelerate -U\n",
    "!pip install ipywidgets\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045a39e-2a3e-4153-bdb5-281500bcd348",
   "metadata": {
    "id": "b045a39e-2a3e-4153-bdb5-281500bcd348"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924e151-27e7-4c40-b735-26a6bc976d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"...\"  # or \"0,1\" for multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b219c9dd-39b6-4a95-b2a1-3f547a1e7bc0",
   "metadata": {
    "id": "b219c9dd-39b6-4a95-b2a1-3f547a1e7bc0"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
   "metadata": {
    "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset, DatasetDict\n",
    "# import numpy as np\n",
    "# from datasets import load_dataset, DatasetDict\n",
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "\n",
    "# dataset = DatasetDict()\n",
    "# train = load_dataset('csv', data_files={'test':\"/path/\", },)\n",
    "#                                    # data_dir=\"/path/\")\n",
    "\n",
    "\n",
    "# eval = load_dataset('csv', data_files={'test':\"/path/\", },)\n",
    "#                                    # data_dir=\"/path/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a8a1d-9fe5-4453-881b-099b8545f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import KFold\n",
    "# from datasets import load_dataset, DatasetDict\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load your dataset\n",
    "# trainset = DatasetDict()\n",
    "# train = load_dataset('csv', data_files={'test': \"/path/\"})\n",
    "# trainset['train'] = train[\"test\"]\n",
    "\n",
    "# # Assuming 'label_column' is the column containing class labels\n",
    "# label_column = 'Sentence'\n",
    "\n",
    "# # Access the dataset using the key and convert it to a DataFrame\n",
    "# train_df = pd.DataFrame(trainset['train'])\n",
    "\n",
    "# # Get the labels\n",
    "# labels = train_df[label_column]\n",
    "\n",
    "\n",
    "# # Create StratifiedKFold object\n",
    "# n_splits = 10  # or any other number of splits you want\n",
    "# kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# # Now make your splits based on the labels\n",
    "# splits = list(kfold.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "# # Finally, do what you want with it\n",
    "# # In this case, I'm overriding the train/val/test\n",
    "\n",
    "# df = pd.DataFrame(splits)\n",
    "# df.to_json(\"/path/file.json\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f56a3-82db-465c-9b86-41795af4a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from datasets import load_dataset, DatasetDict\n",
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# trainset = DatasetDict()\n",
    "# file = open(\"\", index=False)\")\n",
    "# spl = json.load(file)\n",
    "# train = load_dataset('csv', data_files={'test': \"/path/file.csv\"})\n",
    "\n",
    "# trainset['train'] = train[\"test\"]\n",
    "\n",
    "# dataset = DatasetDict()\n",
    "# test_set = trainset[\"train\"].select(spl['1']['9']) #first [] if 0 train and if 1 test, the second [] goes from 0 to 9 for the 10 splits\n",
    "# dataset[\"train\"] = trainset[\"train\"].select(spl['0']['9'])\n",
    "\n",
    "# test_df = pd.DataFrame(test_set)\n",
    "# train_df = pd.DataFrame(dataset[\"train\"])\n",
    "# # print(test_df[test_df['Path']])\n",
    "# print(train_df[train_df[\"Path\"].isin(test_df[\"Path\"])])\n",
    "# # print(dataset[\"train\"])\n",
    "# print(test_df[test_df[\"Path\"].isin(train_df[\"Path\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507e17c-4c0c-4a98-b8e0-c8409e32dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# train_dev = pd.DataFrame(dataset[\"train\"])\n",
    "# dev_df = train_dev.sample(frac=0.1111)\n",
    "# index_names = dev_df.index\n",
    "# dataset[\"dev\"] = dataset[\"train\"].select(index_names)\n",
    "# dev_set = pd.DataFrame(dataset[\"dev\"])\n",
    "# dev_set.to_csv(\"/path/file.csv\", index=False)\n",
    "# train_df = train_dev.drop(index_names, inplace = False)\n",
    "# index_names = train_df.index\n",
    "# dataset[\"train\"] = dataset[\"train\"].select(index_names)\n",
    "# tra_set = pd.DataFrame(dataset[\"train\"])\n",
    "# tra_set.to_csv(\"/path/file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362aebaa-6445-4b26-9696-30304d4cb82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "dataset = DatasetDict()\n",
    "\n",
    "train = load_dataset('csv', data_files={'test': \"/path/file.csv\"})\n",
    "dev = load_dataset('csv', data_files={'dev': \"/path/file.csv\"})\n",
    "\n",
    "dataset[\"train\"] = train[\"test\"]\n",
    "dataset[\"dev\"] = dev[\"dev\"]\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29f8ee-66d3-42eb-9e2d-cb14e55e0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.DataFrame(test_set)\n",
    "# train_df = pd.DataFrame(dataset[\"train\"])\n",
    "# print(test_df[test_df[\"Path\"].isin(train_df[\"Path\"])])\n",
    "# print(train_df[train_df[\"Path\"].isin(test_df[\"Path\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167dfeb-b3e7-4828-8f99-0106c21fa45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np1 = np.array(spl['1']['9'])\n",
    "# np2 = np.array(spl['0']['9'])\n",
    "\n",
    "# any(np.isin(np2,np1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657cea9a-0dee-4d73-8cfd-bed9b39eccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)\n",
    "# print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba635d-518c-47ac-97ee-3cad25f1e0ce",
   "metadata": {
    "id": "20ba635d-518c-47ac-97ee-3cad25f1e0ce"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(\n",
    "    [\"Unnamed: 0\",\"Root\", \"DialectRegion\", \"Age\", \"SpeakerID\", \"Group\", \"Gender\", \"Duration (seconds)\", \"Duration (days)\", \"CEF\", \"Component\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db117809-7f11-4c5f-b91c-4ab3c0b16a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chars_to_remove_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\‚Äú\\%\\‚Äò\\‚Äù\\ÔøΩ\\']'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"Sentence\"] = re.sub(chars_to_remove_regex, '', batch[\"Sentence\"]).lower()\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55b6df-64f6-467c-bcb0-517b7c0a45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].map(remove_special_characters)\n",
    "dataset['dev'] = dataset['dev'].map(remove_special_characters)\n",
    "# test_set = test_set.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5",
   "metadata": {
    "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe20eb-53e4-4e36-8504-96108545aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large-v2\", language=\"Dutch\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9f0c5-8607-4642-a8ac-c3ab2e223ea6",
   "metadata": {
    "id": "77d9f0c5-8607-4642-a8ac-c3ab2e223ea6"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\", language=\"Dutch\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b0ec5-0c94-4e2c-ae24-c791be1b2255",
   "metadata": {
    "id": "6e6b0ec5-0c94-4e2c-ae24-c791be1b2255"
   },
   "outputs": [],
   "source": [
    "print(dataset[\"train\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e2e57-156f-417b-8cfb-69221cc198e8",
   "metadata": {
    "id": "f12e2e57-156f-417b-8cfb-69221cc198e8"
   },
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "dataset = dataset.cast_column(\"Path\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87122d71-289a-466a-afcf-fa354b18946b",
   "metadata": {
    "id": "87122d71-289a-466a-afcf-fa354b18946b"
   },
   "outputs": [],
   "source": [
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525c478-8962-4394-a1c4-103c54cce170",
   "metadata": {
    "id": "6525c478-8962-4394-a1c4-103c54cce170"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"Path\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"Sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b",
   "metadata": {
    "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names[\"train\"], num_proc=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9fa37-e90f-4749-a9b8-35fbfb7ab167",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"whisper-9-dutch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f7ae19-bdb6-4008-91ad-b94deddf45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5",
   "metadata": {
    "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc834702-c0d3-4a96-b101-7b87be32bf42",
   "metadata": {
    "id": "fc834702-c0d3-4a96-b101-7b87be32bf42"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b4011-f31f-4b57-b684-c52332f92890",
   "metadata": {
    "id": "b22b4011-f31f-4b57-b684-c52332f92890"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23959a70-22d0-4ffe-9fa1-72b61e75bb52",
   "metadata": {
    "id": "23959a70-22d0-4ffe-9fa1-72b61e75bb52"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b54211-b2c7-4e5a-8232-337e5d834dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set random seed for PyTorch\n",
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f",
   "metadata": {
    "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62038ba3-88ed-4fce-84db-338f50dcd04f",
   "metadata": {
    "id": "62038ba3-88ed-4fce-84db-338f50dcd04f"
   },
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a",
   "metadata": {
    "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-9-dutch\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=12,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=3e-05,\n",
    "    warmup_steps=20,\n",
    "    num_train_epochs=5,\n",
    "    gradient_checkpointing=True,\n",
    "    bf16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_total_limit = 2,\n",
    "    save_steps=30,\n",
    "    eval_steps=30,\n",
    "    logging_steps=30,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546d7fe-0543-479a-b708-2ebabec19493",
   "metadata": {
    "id": "d546d7fe-0543-479a-b708-2ebabec19493"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, EarlyStoppingCallback\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"dev\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    # callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.01)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-2zQwMfEOBJq",
   "metadata": {
    "id": "-2zQwMfEOBJq"
   },
   "outputs": [],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8fe6f9-2200-400f-b227-191d3e9919ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.random_seed = seed_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f490e3-71b2-4164-be7b-f02abe3ced26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import cuda \n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de",
   "metadata": {
    "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704f91e-241b-48c9-b8e0-f0da396a9663",
   "metadata": {
    "id": "c704f91e-241b-48c9-b8e0-f0da396a9663"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    # \"dataset_tags\": \"Jasmin-CGN\",\n",
    "    # \"dataset\": \"Group 5: native adults above 65\",  # a 'pretty' name for the training dataset\n",
    "    # \"dataset_args\": \"config: hi, split: test\",\n",
    "    \"language\": \"nl\",\n",
    "    \"model_name\": \"Whisper Large V2\",  # a 'pretty' name for our model\n",
    "    \"finetuned_from\": \"openai/whisper-large-v2\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "    # \"tags\": \"hf-asr-leaderboard\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7030622-caf7-4039-939b-6195cdaa2585",
   "metadata": {
    "id": "d7030622-caf7-4039-939b-6195cdaa2585"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029c2bb-3709-4154-9f6d-93c11cb8ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Download a static FFmpeg build and add it to PATH.\n",
    "# !curl https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz -o ffmpeg.tar.xz \\\n",
    "#  && tar -xf ffmpeg.tar.xz && rm ffmpeg.tar.xz\n",
    "# ffmdir = !find . -iname ffmpeg-*-static\n",
    "# path = %env PATH\n",
    "# path = path + ':' + ffmdir[0]\n",
    "# %env PATH $path\n",
    "\n",
    "# print('')\n",
    "# !which ffmpeg\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46106a-6a18-42d9-a7ca-e3b17915b9ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from datasets import load_dataset, load_metric, Audio, ClassLabel, load_from_disk, Features, Value\n",
    "# import evaluate\n",
    "\n",
    "# # IMPORTANT: for openai/whisper models: You can change the \"language\" attribute to transcribe in a different language.\n",
    "# # If \"language\" is not mentioned, Whisper will translate the audio to English by default (or transcribe to English if the audio\n",
    "# # is in English)\n",
    "# transcriber = pipeline(\"automatic-speech-recognition\", model='modddddddel/whisper-native-elderly-9-dutch', device=0,\n",
    "#                       generate_kwargs = {\"language\":\"<|nl|>\",\"task\": \"transcribe\"},)\n",
    "\n",
    "# wer = evaluate.load(\"wer\")\n",
    "# labels = []\n",
    "# preds = []\n",
    "# i = 0\n",
    "# print(dataset)\n",
    "# for recording in test_set:\n",
    "#     label = labels.append(recording['Sentence'])\n",
    "#     pred = preds.append(transcriber(recording['Path'])['text'])\n",
    "#     i += 1\n",
    "#     print(str(i) + '/' + str(len(test_set)))\n",
    "#     print('predicted: ' + preds[i-1])\n",
    "#     print('actual: ' + labels[i-1])\n",
    "\n",
    "# # Recommended: save the results in a CSV file to use later for comparison\n",
    "# # (to avoid having to run the model(s) again)\n",
    "# df = pd.DataFrame({'reference': labels, 'hypothesis': preds})\n",
    "# df.to_csv('/path/file.csv')\n",
    "\n",
    "# print( 100 * wer.compute(predictions=preds, references=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded23007-1117-4f41-8a51-0626f3261189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the CSV file into a DataFrame\n",
    "# file_path = \"/path/file.csv\"\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# # Apply the regex operation to the 'hypothesis' column\n",
    "# df['hypothesis'] = df['hypothesis'].replace(r'ÔøΩ\\s*', '', regex=True)\n",
    "\n",
    "# # Save the modified DataFrame to a new CSV file\n",
    "# output_file_path = \"/path/file.csv\"\n",
    "# df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0dec3-d560-4fb9-9b73-f54750106fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import jiwer\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('/path/file.csv')\n",
    "\n",
    "# out = jiwer.process_words(\n",
    "#     df['reference'].values.tolist(),\n",
    "#     df['hypothesis'].values.tolist(),\n",
    "# )\n",
    "\n",
    "# print(jiwer.visualize_alignment(out))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
