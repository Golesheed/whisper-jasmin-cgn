{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub import AudioSegment, effects \n",
    "from scipy.io.wavfile import read, write\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "# Pass audio path\n",
    "comp_p = [f for f in listdir('/path/Data/data/audio/wav/comp-p/nl/') if isfile(join('/path/Data/data/audio/wav/comp-p/nl/', f))]\n",
    "\n",
    "\n",
    "for file in comp_p:\n",
    "    print(file)\n",
    "    rate, audio = read('/path/Data/data/audio/wav/comp-p/nl/' + file)\n",
    "    # make the audio in pydub audio segment format\n",
    "    aud = AudioSegment(audio.tobytes(),frame_rate = rate,\n",
    "                         sample_width = audio.dtype.itemsize,channels = 2)\n",
    "    channels = AudioSegment.split_to_mono(aud)\n",
    "    # use split on sience method to split the audio based on the silence, \n",
    "    # here we can pass the min_silence_len as silent length threshold in ms and intensity thershold\n",
    "    audio_chunks = split_on_silence(\n",
    "        channels[0],\n",
    "        min_silence_len = 2000,\n",
    "        silence_thresh = -45,\n",
    "        keep_silence = 500,)\n",
    "    #audio chunks are combined here\n",
    "    audio_processed = sum(audio_chunks)\n",
    "    if audio_processed==0:\n",
    "        continue\n",
    "#         write('/path/Data/data/audio/wav/comp-p-silenced/nl/'+ file, rate, channels[0])\n",
    "\n",
    "    else:\n",
    "        audio_processed = np.array(audio_processed.get_array_of_samples())\n",
    "        #Note the processed audio rate is not the same - it would be 1K\n",
    "        write('/path/Data/data/audio/wav/comp-p-silenced/nl/'+ file, rate, audio_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn000047.wavdone\n",
      "fn000155.wav\n",
      "fn000155.wavdone\n",
      "fn000147.wav\n",
      "fn000147.wavdone\n",
      "fn100237.wav\n",
      "fn100237.wavdone\n",
      "fn100155.wav\n",
      "fn100155.wavdone\n",
      "fn000497.wav\n",
      "fn000497.wavdone\n",
      "fn000688.wav\n",
      "fn000688.wavdone\n",
      "fn100012.wav\n",
      "fn100012.wavdone\n",
      "fn000092.wav\n",
      "fn000092.wavdone\n",
      "fn000649.wav\n",
      "fn000649.wavdone\n",
      "fn000078.wav\n",
      "fn000078.wavdone\n",
      "fn100257.wav\n",
      "fn100257.wavdone\n",
      "fn000037.wav\n",
      "fn000037.wavdone\n",
      "fn000117.wav\n",
      "fn000117.wavdone\n",
      "fn100227.wav\n",
      "fn100227.wavdone\n",
      "fn000609.wav\n",
      "fn000609.wavdone\n",
      "fn000143.wav\n",
      "fn000143.wavdone\n",
      "fn000685.wav\n",
      "fn000685.wavdone\n",
      "fn000754.wav\n",
      "fn000754.wavdone\n",
      "fn000543.wav\n",
      "fn000543.wavdone\n",
      "fn000663.wav\n",
      "fn000663.wavdone\n",
      "fn000789.wav\n",
      "fn000789.wavdone\n",
      "fn000082.wav\n",
      "fn000082.wavdone\n",
      "fn000546.wav\n",
      "fn000546.wavdone\n",
      "fn000612.wav\n",
      "fn000612.wavdone\n",
      "fn000758.wav\n",
      "fn000758.wavdone\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub import AudioSegment, effects \n",
    "from scipy.io.wavfile import read, write\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "# Pass audio path\n",
    "comp_q = [f for f in listdir('/path/Data/data/audio/wav/comp-q/nl/') if isfile(join('/path/Data/data/audio/wav/comp-q/nl/', f))]\n",
    "for file in comp_q:\n",
    "    print(file)\n",
    "    rate, audio = read('/path/Data/data/audio/wav/comp-q/nl/' + file)\n",
    "    # make the audio in pydub audio segment format\n",
    "    aud = AudioSegment(audio.tobytes(),frame_rate = rate,\n",
    "                         sample_width = audio.dtype.itemsize,channels = 1)\n",
    "    # use split on sience method to split the audio based on the silence, \n",
    "    # here we can pass the min_silence_len as silent length threshold in ms and intensity thershold\n",
    "    audio_chunks = split_on_silence(\n",
    "        aud,\n",
    "        min_silence_len = 2000,\n",
    "        silence_thresh = -45,\n",
    "        keep_silence = 500,)\n",
    "    #audio chunks are combined here\n",
    "    audio_processed = sum(audio_chunks)\n",
    "    if audio_processed==0:\n",
    "        continue\n",
    "# write('/path/Data/data/audio/wav/comp-q-silenced/nl/'+ file, rate, channels[0])\n",
    "    else:\n",
    "        audio_processed = np.array(audio_processed.get_array_of_samples())\n",
    "        #Note the processed audio rate is not the same - it would be 1K\n",
    "        print(file + 'done')\n",
    "        write('/path/Data/data/audio/wav/comp-q-silenced/nl/'+ file, rate, audio_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
